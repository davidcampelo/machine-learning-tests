{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot enconding\n",
    "\n",
    "Usually a machine learning algoritmh understands numerical data only. Other kinds of data, also called categorical, carries a limited number of values. For example, if one wants to store car brands, the values would be categorical (because the answers would be things like Honda, Toyota, Ford, None, etc.). So this values must be encoded before being passed to a machine learning models in Python. \n",
    "\n",
    "The most popular standard Approach for Categorical Data is the *One-hot encoding*. One hot encoding creates new (binary) columns, indicating the presence of each possible value from the original data. It works very well unless your categorical variable takes on a large number of values (i.e. you generally won't it for variables taking more than 15 different values. It'd be a poor choice in some cases with fewer values, though that varies.)[1]\n",
    " \n",
    "In this notebook we're using the home prices using dataset from Iowa, USA.\n",
    "\n",
    "(Inspired by a tutorial published at www.kaggle.com)\n",
    "\n",
    "[1] https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size=1460 Test dataset size=1459\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/iowa_train.csv')\n",
    "df_test = pd.read_csv('data/iowa_test.csv')\n",
    "\n",
    "# Drop houses where the target value for prediction is not defined (!)\n",
    "df_train.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "print(\"Train dataset size={} Test dataset size={}\".format(df_train.shape[0], df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning data and selecting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns with missing values. Also removing **Id** and **SalesPrice** as these columns does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in df_train.columns \n",
    "                                 if df_train[col].isnull().any()]                                  \n",
    "\n",
    "# Loading predictors and target (X/y) \n",
    "X_train = df_train.drop(['Id', 'SalePrice'] + cols_with_missing, axis=1)\n",
    "y_train = df_train.SalePrice\n",
    "X_test  = df_test.drop(['Id'] + cols_with_missing, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just considering numeric columns and columns with low cardinality, which is the number of unique values in a column. We use it as our only way to select categorical columns here. This is convenient, though a little arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of columns used as predictors = 57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LowQualFinSF     int64\n",
       "SaleType        object\n",
       "Utilities       object\n",
       "BsmtFinSF2       int64\n",
       "LotShape        object\n",
       "OpenPorchSF      int64\n",
       "BsmtHalfBath     int64\n",
       "GarageCars       int64\n",
       "HouseStyle      object\n",
       "LotConfig       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_cardinality_cols = [cname for cname in X_train.columns if \n",
    "                                X_train[cname].nunique() < 10 and\n",
    "                                X_train[cname].dtype == \"object\"]\n",
    "numeric_cols = [cname for cname in X_train.columns if \n",
    "                                X_train[cname].dtype in ['int64', 'float64']]\n",
    "cols = low_cardinality_cols + numeric_cols\n",
    "\n",
    "X_train = X_train[cols]\n",
    "X_test  = X_test[cols]\n",
    "print(\"Amount of columns used as predictors = {}\".format(len(cols)))\n",
    "X_train.dtypes.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to return MAE using cross_val_score (k-folding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(X, y):\n",
    "    # multiple by -1 to make positive MAE score instead of neg value returned as sklearn convention\n",
    "    return -1 * cross_val_score(RandomForestRegressor(50), \n",
    "                                X, y, \n",
    "                                scoring = 'neg_mean_absolute_error').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trying some features set configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In  order to see how the configurations perform, it's calculated the **Mean absolute error** of models built with these different sets of features. One-Hot Encoding may vary on a case-by-case basis. In the Models 2 and 3, it seems not to have any great benefit from using the one-hot encoded variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Not considering categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of SalePrice when Dropping Categoricals = 18,562\n"
     ]
    }
   ],
   "source": [
    "X_train_new = X_train.select_dtypes(exclude=['object'])\n",
    "\n",
    "print('MAE of SalePrice when Dropping Categoricals = {:,.0f}'.format(get_mae(X_train_new, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Using One-Hot Encoding (get_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of SalePrice when Dropping Categoricals = 18,306\n"
     ]
    }
   ],
   "source": [
    "X_train_new = pd.get_dummies(X_train)\n",
    "\n",
    "print('MAE of SalePrice when Dropping Categoricals = {:,.0f}'.format(get_mae(X_train_new, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - Considering data from test dataset also\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = pd.get_dummies(X_train)\n",
    "X_test_new = pd.get_dummies(X_test)\n",
    "a,b = X_train_new.align(X_test_new, join='left', axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
